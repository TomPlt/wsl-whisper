#!/usr/bin/env bash
# Transcribe audio/video files using faster-whisper
# Usage: whisper <file> [model] [language]
#   model: tiny, base, small, medium, large-v3 (default: base)
#   language: en, es, fr, etc. (default: auto-detect)

set -euo pipefail

if [ $# -lt 1 ]; then
    echo "Usage: whisper <audio/video file> [model] [language]"
    echo ""
    echo "Models (speed vs accuracy):"
    echo "  tiny   - fastest, least accurate"
    echo "  base   - fast, good accuracy (default)"
    echo "  small  - balanced"
    echo "  medium - slower, better accuracy"
    echo "  large-v3 - slowest, best accuracy"
    echo ""
    echo "Examples:"
    echo "  whisper recording.mp3"
    echo "  whisper meeting.wav medium"
    echo "  whisper video.mp4 base en"
    exit 1
fi

FILE="$1"
MODEL="${2:-base}"
LANG_ARG="${3:-}"

if [ ! -f "$FILE" ]; then
    echo "Error: File not found: $FILE"
    exit 1
fi

LANG_OPT=""
if [ -n "$LANG_ARG" ]; then
    LANG_OPT=", language=\"$LANG_ARG\""
fi

"$(dirname "$(realpath "$0")")/.venv/bin/python3" -c "
import ctypes, os, sys
_cublas = os.path.join(sys.prefix, 'lib', f'python{sys.version_info.major}.{sys.version_info.minor}',
    'site-packages', 'nvidia', 'cublas', 'lib', 'libcublas.so.12')
if os.path.exists(_cublas): ctypes.cdll.LoadLibrary(_cublas)
from faster_whisper import WhisperModel

model = WhisperModel('$MODEL', device='cuda', compute_type='float16')
segments, info = model.transcribe('$FILE'$LANG_OPT, beam_size=5)

print(f'Detected language: {info.language} (probability {info.language_probability:.2f})')
print(f'Duration: {info.duration:.1f}s')
print('---')

for segment in segments:
    print(f'[{segment.start:.1f}s -> {segment.end:.1f}s] {segment.text.strip()}')
"
